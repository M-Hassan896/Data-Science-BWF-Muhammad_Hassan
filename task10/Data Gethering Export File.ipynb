{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with export File\n",
    "df=pd.read_csv('export.csv')\n",
    "df.head()\n",
    "temp=df.groupby(\"Country\")[\"Batsman_runs\"].sum().reset_index()\n",
    "temp.to_csv('batsman_runs.csv',index=False)#index=False is used to remove the index column from the csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting to Excel\n",
    "temp=df.groupby(\"Country\")[\"Batsman_runs\"].sum().reset_index()\n",
    "temp.to_excel('batsman_runs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ecporting to multiple sheets\n",
    "with pd.ExcelWriter('batsman_runs.xlsx') as writer:\n",
    "    temp.to_excel(writer,sheet_name='batsman_runs')\n",
    "    df.to_excel(writer,sheet_name='original_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting to HTML\n",
    "temp=df.groupby(\"Country\")[\"Batsman_runs\"].sum().reset_index()\n",
    "temp.to_html('batsman_runs.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('Country==\"India\"').to_html('india.html')#query is used to filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting to JSON\n",
    "df.groupby(['Country','Batsman'])['Batsman_runs'].sum().unstack().to_json('batsman_runs.json',orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting to SQL\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "engine=create_engine('mysql+pymysql://root:@localhost/ipl')\n",
    "df.to_sql('ipl_data',engine,index=False,if_exists='append')#if_exists='replace' is used to replace the table if it already exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with API\n",
    "import pandas as pd\n",
    "import requests\n",
    "response=requests.get('https://api.covid19india.org/data.json')\n",
    "temp_df=pd.DataFrame(response.json()[results]).head()[['state','active','confirmed','deaths','recovered']] #results is the key in the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "for i in range(0,100):\n",
    "    response=requests.get('https://api.covid19india.org/data.jsonpage={}'.format(i))\n",
    "    temp_df=pd.DataFrame(response.json()['statewise']).head()[['state','active','confirmed','deaths','recovered']]\n",
    "    df=df.append(temp_df,ignore_index=True)#ignore_index=True is used to ignore the index of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rapid API visit to get the API key and make the data sets\n",
    "#JSON viewer chrome extension to view the json file in a structured way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Web Scrapping \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)Chrome/83.0.4103.116 Safari/537.36'}\n",
    "webpage=requests.get('https://www.espncricinfo.com/rankings/content/page/211271.html',headers=headers).text\n",
    "soup=BeautifulSoup(webpage,'lxml')#lxml is the parser\n",
    "print(soup.prettify())#prettify is used to view the html file in a structured way\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(\"h1\").text #find_all is used to find all the tags with the given name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all(\"h2\"):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company=soup.find_all(\"div\",class_=\"company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "rating=[]\n",
    "reviews=[]\n",
    "ctype=[]\n",
    "hq=[]\n",
    "old=[]\n",
    "employees=[]\n",
    "for i in company:\n",
    "    name.append(i.find('h3').text)\n",
    "    rating.append(i.find('span',class_='rating').text)\n",
    "    reviews.append(i.find('span',class_='reviews').text)\n",
    "    ctype.append(i.find('div',class_='company__type').text)\n",
    "    hq.append(i.find('div',class_='company__location').text)\n",
    "    old.append(i.find('div',class_='company__age').text)\n",
    "    employees.append(i.find('div',class_='company__employees').text)\n",
    "    \n",
    "company[0].find_all('div',class_='company__location')[0].text.strip()#strip is used to remove the spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
